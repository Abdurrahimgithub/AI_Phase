#  Fake News Detection Using  NLP

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)<br>
<img title="a title" alt="Alt text" src="https://raw.githubusercontent.com/Abdurrahimgithub/AI_Phase/ca6267eb42122254754c02b82400abbfe7615341/AI_Phase5/Source%20Code/Image/Python-3.12-.svg"><br>
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)
![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white)
![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)

<img title="a title" alt="Alt text" src="https://media.licdn.com/dms/image/D5605AQFeAbKNlyhrIw/videocover-low/0/1695299034890?e=2147483647&v=beta&t=5nq9k620cfBSI1hYBXiZNx0hvlrCAb5GBuJef2WL3Zs">

## Project Overview

**This project aims to build a machine learning model for the detection of fake news articles using Natural Language Processing (NLP) techniques. The model will analyze textual data from news articles and classify them as either "real" or "fake." This README file provides an overview of the project, details about the dataset used, and submission information.**

## Dataset

### Dataset Description

The project utilizes two datasets:
1. `true.csv`: A dataset containing real news articles.
2. `fake.csv`: A dataset containing fake news articles.

Each dataset includes columns for the article title, text, subject, and date.

### Dataset Source

The datasets were obtained from [Dataset Source Link](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset).

## Code and Project Structure

The project code and files are organized as follows:

**Project Path:** `AI_Phase5/Source code/`

- `Jupyter notebook/dataset/`: Directory containing the datasets `true.csv` and `fake.csv`.
- `jupyter notebooks/`: Jupyter notebooks for data preprocessing, model training, and evaluation.
- `static/`: Saved css files.
- `template/`: Saved HTML and JAVASCRIPT files
- `README.md`: This documentation files.
- `requirements.txt`: List of Python packages and dependencies required for the project.
- `main.py`: The main Python script for executing the project.
  
# AI_Phase
This is Fake News Detection Phase Project Document in IBM NAAN MUDHALVAN

# Phase Of Development 
- **AI_Phase1**
    * AI_Phase1.pdf
- **AI_phase2**
    * AI_Phase2.pdf
- **AI_phase3**
    * AI_Phase3.pdf
    *  AI_Phase3.ipynb      
- **AI_phase4**
    * AI_Phase4.pdf
    * AI_Phase4.ipynb
- **AI_phase5**
    * AI_Phase5.pdf
    * Source Code
        * Main.py
        * README.md

# AI_Phase1
**Phase 1: Problem Definition and Design Thinking** 

*In this part you will need to understand the problem statement and create a document on what have you understood and how will you proceed ahead with solving the problem. Please think on a design and present in form of a document.*

# AI_Phase2
**Phase 2: Innovation**

*In this phase, we can explore innovative techniques such as ensemble methods and deep learning architectures to improve the prediction system's accuracy and robustness.
Consider exploring advanced techniques like deep learning models (e.g., LSTM, BERT) for improved fake news detection accuracy.*

# AI_Phase3
**Phase 3: Development Part 1**

*In this part you will begin building your project by loading and preprocessing the dataset. 
Begin building the fake news detection model by loading and preprocessing the dataset. 
Load the fake news dataset and preprocess the textual data.*

# AI_Phase4
**Phase 4: Development Part 2**

*In this part you will continue building your project. 
Continue building the fake news detection model by applying NLP techniques and training a classification model. 
Text Preprocessing and Feature Extraction 
Model training and evaluation.*

# AI_Phase5

**Phase 5: Project Documentation & Submission**

In this part you will document your project and prepare it for submission.

**Documentation**

- Clearly outline the problem statement, design thinking process, and the phases of development.
- Describe the dataset used, data preprocessing steps, and feature extraction techniques.
- Explain the choice of classification algorithm and model training process.

**Submission**

- Compile all the code files, including the data preprocessing, model training, and evaluation steps.
- Provide a well-structured README file that explains how to run the code and any dependencies.
- Include the dataset source and a brief description.
- Share the submission on platforms like GitHub or personal portfolio for others to access and review.*


